{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragmentation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'll do the entire fragmentation procedure. The goal will be to get a set of pure fragments for use in the paper. We'll focus on bringing down the purity value of all fragments to 0.02. Then, when we do the buffer region generation, we'll do it on a per fragment basis, and not per atom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CheSS import Matrices as M\n",
    "\n",
    "class blockparam:\n",
    "    def __init__(self, folder):\n",
    "        self.density_file = folder+\"/density_kernel_sparse.mtx\"\n",
    "        self.hamiltonian_file = folder+\"/hamiltonian_sparse.mtx\"\n",
    "        self.overlap_file = folder+\"/overlap_sparse.mtx\"\n",
    "        self.metadata_file = folder+\"/sparsematrix_metadata.dat\"\n",
    "        \n",
    "    def build_lookup(self):\n",
    "        alookup = M.get_atomic_lookup(self.metadata_file)\n",
    "        self.atom_to_basis = [[] for x in range(0, max(alookup)+1)]\n",
    "        for basis, atom in enumerate(alookup):\n",
    "            self.atom_to_basis[atom].append(basis)\n",
    "    \n",
    "    def read_matrices(self):\n",
    "        from scipy.io import mmread\n",
    "        from scipy.sparse.linalg import inv\n",
    "        self.overlap = mmread(self.overlap_file)\n",
    "        self.density = mmread(self.density_file)\n",
    "        self.hamiltonian = mmread(self.hamiltonian_file)\n",
    "        self.KS = 0.5*self.density.dot(self.overlap).todense()\n",
    "        self.sinv = inv(self.overlap)\n",
    "        self.sinvxh = self.sinv.dot(self.hamiltonian)\n",
    "        self.sinvxh2 = self.sinvxh.dot(self.sinvxh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = blockparam(\"Matrices\")\n",
    "data.build_lookup()\n",
    "data.read_matrices()\n",
    "geom_file = \"Matrices/1L2Y.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BigDFT import Fragments as F\n",
    "from yaml import load\n",
    "with open(geom_file) as ifile:\n",
    "    sys = load(ifile)\n",
    "    positions = sys[\"Reading positions\"].itervalues().next()\n",
    "fdict = F.CreateFragDict(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "electron_lookup = {'H' :1, 'He':2, \n",
    "                   'Li':1, 'Be':2, 'B' :3, 'C': 4, 'N':5, 'O':6, 'F' :7, 'Ne':8,\n",
    "                   'Na':1, 'Mg':2, 'Al':3, 'Si':4, 'P':5, 'S':6, 'Cl':7}\n",
    "natoms = len(positions[\"positions\"])\n",
    "charge = zeros((natoms))\n",
    "for i, p in enumerate(positions[\"positions\"]):\n",
    "    name = p.keys()[1]\n",
    "    charge[i] = electron_lookup[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do the analysis of the purity of each fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_purity(param, charge, frag):\n",
    "    from numpy import zeros\n",
    "    from numpy import trace\n",
    "    from scipy.sparse import csr_matrix\n",
    "    if (len(frag)) == 0:\n",
    "        return 0\n",
    "    indices = []\n",
    "    cv = 0\n",
    "    for atom in frag:\n",
    "        indices += param.atom_to_basis[atom-1]\n",
    "        cv += charge[atom-1]\n",
    "\n",
    "    submat = param.KS[indices,:]\n",
    "    submat = submat[:,indices]\n",
    "    \n",
    "    return -2*trace(submat.dot(submat) - submat)/cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some code to compute, categorize and plot the purity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_purity(frag_dict):\n",
    "    # First create a list for the purity value function\n",
    "    frag_lists = {\"Protein\":[], \"Water\":[], \"Ions\":[]}\n",
    "    for fname in frag_dict.keys():\n",
    "        for fid in frag_dict[fname].keys():\n",
    "            if \"WAT\" in fname:\n",
    "                frag_lists[\"Water\"].append(frag_dict[fname][fid])\n",
    "            elif \"SOD\" in fname or \"CLA\" in fname or \"Cl\" in fname:\n",
    "                frag_lists[\"Ions\"].append(frag_dict[fname][fid])\n",
    "            else:\n",
    "                frag_lists[\"Protein\"].append(frag_dict[fname][fid])\n",
    "            \n",
    "    # Compute\n",
    "    purity_values = {\"Protein\":[], \"Water\":[], \"Ions\":[]}\n",
    "    for category in frag_lists:\n",
    "        for frag in frag_lists[category]:\n",
    "            purity_values[category].append(compute_purity(data, charge, frag))\n",
    "        \n",
    "    from matplotlib import pyplot as plt\n",
    "    import matplotlib.ticker as plticker\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(14,4), sharex=False, sharey=True,\n",
    "                      gridspec_kw = {'width_ratios':[4, 3, 2\n",
    "                                                    ]})\n",
    "    for i, cat in enumerate([\"Protein\", \"Water\", \"Ions\"]):\n",
    "        axs[i].plot(range(0, len(purity_values[cat])), purity_values[cat], 'x')\n",
    "        axs[i].margins(x=0.1,y=0.1)\n",
    "    loc = plticker.MultipleLocator(base=1.0)\n",
    "    axs[2].xaxis.set_major_locator(loc)\n",
    "    axs[0].set_ylabel(\"Purity Value\", fontsize=12)\n",
    "    axs[0].set_xlabel(\"Protein Residues\", fontsize=12)\n",
    "    axs[1].set_xlabel(\"Water Residues\", fontsize=12)\n",
    "    axs[2].set_xlabel(\"Ion Residues\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the default fragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_purity(fdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cl Refragmentation\n",
    "We'll now perform the refragmentation analysis. First, we will refragment the ions in solution (Na+Cl). For that purpose, we will merge the ion atoms with their three nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNearest(fragtuple, sysfile, threshold=None, number=None):\n",
    "    import numpy as np\n",
    "    sys = F.System(posinp_dict=sysfile)\n",
    "    for f in sys.fragments:\n",
    "        if f.id == F.SetFragId(*fragtuple):\n",
    "            our_frag = f\n",
    "            break\n",
    "    distance_array =[F.distance(our_frag, f, cell=sysfile[\"cell\"]) for f in sys.fragments]\n",
    "    ipiv = np.argsort(distance_array)\n",
    "    if number:\n",
    "        shell = ipiv[:number]\n",
    "    else:\n",
    "        shell = np.where(np.array(distance_array) < threshold)[0]\n",
    "    shellid = [sys.fragments[s].id for s in shell]\n",
    "    return shellid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clcluster568 = GetNearest((\"CLA\",568), positions, number=3+1)\n",
    "for near in clcluster568:\n",
    "    fname, fid = near.split(\":\")\n",
    "    print(near, compute_purity(data, charge, fdict[fname][int(fid)]))\n",
    "print()\n",
    "\n",
    "clcluster567 = GetNearest((\"CLA\",567), positions, number=3+1)\n",
    "for near in clcluster567:\n",
    "    fname, fid = near.split(\":\")\n",
    "    print(near, compute_purity(data, charge, fdict[fname][int(fid)]))\n",
    "print()\n",
    "\n",
    "nacluster = GetNearest((\"SOD\",566), positions, number=3+1)\n",
    "for near in nacluster:\n",
    "    fname, fid = near.split(\":\")\n",
    "    print(near, compute_purity(data, charge, fdict[fname][int(fid)]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the fragment dictioanry with these new merged fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "re_dict = deepcopy(fdict)\n",
    "\n",
    "re_dict[\"Cl Cluster\"] = {}\n",
    "re_dict[\"Na Cluster\"] = {}\n",
    "\n",
    "re_dict[\"Cl Cluster\"][567] = []\n",
    "for f in clcluster567:\n",
    "    fname, fid = f.split(\":\")\n",
    "    re_dict[\"Cl Cluster\"][567] += fdict[fname][int(fid)]\n",
    "    del re_dict[fname][int(fid)]\n",
    "    \n",
    "re_dict[\"Cl Cluster\"][568] = []\n",
    "for f in clcluster568:\n",
    "    fname, fid = f.split(\":\")\n",
    "    re_dict[\"Cl Cluster\"][568] += fdict[fname][int(fid)]\n",
    "    del re_dict[fname][int(fid)]\n",
    "   \n",
    "re_dict[\"Na Cluster\"][566] = []\n",
    "for f in nacluster:\n",
    "    fname, fid = f.split(\":\")\n",
    "    re_dict[\"Na Cluster\"][566] += fdict[fname][int(fid)]\n",
    "    del re_dict[fname][int(fid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the purity values after the chlorine clusters have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_purity(re_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Refragmentation\n",
    "Now we need to refragment the protein residues. First, let's extract the protein residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dict = {}\n",
    "for fname in re_dict.keys():\n",
    "    if not \"CLA\" in fname and \"Cl\" not in fname and \"SOD\" not in fname and \"WAT\" not in fname:\n",
    "        if not fname in pro_dict:\n",
    "            pro_dict[fname] = {} \n",
    "        for fid in re_dict[fname].keys():\n",
    "            pro_dict[fname][int(fid)] = re_dict[fname][fid]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the plot with labels function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_protein(dict_list, title, file_name=None):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    import numpy.ma as ma\n",
    "    \n",
    "    fig, ax = plt.subplots(len(dict_list),1,figsize=(8,8))\n",
    "    \n",
    "    if len(dict_list) == 1:\n",
    "        ax = [ax]\n",
    "    \n",
    "    for axi, ldict in enumerate(dict_list):\n",
    "        labels = []\n",
    "        purity = []\n",
    "        odd = []\n",
    "        for i in range(0, 21):\n",
    "            labels.append(\"\")\n",
    "            purity.append(-1)\n",
    "            odd.append(\"\")\n",
    "        for fname in ldict.keys():\n",
    "            for fid in ldict[fname].keys():\n",
    "                labels[int(fid)-1] = fname\n",
    "                purity[int(fid)-1] = compute_purity(data,charge,ldict[fname][fid])\n",
    "                cv = 0\n",
    "                for atom in ldict[fname][fid]:\n",
    "                    cv += charge[atom-1]\n",
    "                if int(cv) % 2 == 0:\n",
    "                    odd[int(fid)-1] = False\n",
    "                else:\n",
    "                    odd[int(fid)-1] = True\n",
    "\n",
    "        labels[-1] = \"Full Protein\"\n",
    "        full_atom = []\n",
    "        for fname in ldict:\n",
    "            for fid in ldict[fname]:\n",
    "                full_atom.extend(ldict[fname][fid])\n",
    "        purity[-1] = compute_purity(data, charge, full_atom)\n",
    "\n",
    "        ax[axi].plot(ma.array(purity, mask=odd), 'x', color=\"r\", markersize=10, label=\"Even Electrons\")\n",
    "        ax[axi].plot(ma.array(purity, mask=[not x for x in odd]), '+', color=\"g\", markersize=10,\n",
    "                label=\"Odd Electrons\")\n",
    "\n",
    "        ax[axi].set_ylabel(\"Purity Value\", fontsize=12)\n",
    "        ax[axi].set_xlim(-1,21)\n",
    "        ax[axi].set_ylim(0, 0.1)\n",
    "\n",
    "        ax[axi].axhline(0.025, color=\"black\", linestyle=\"--\", label=\"Purity 0.025\")\n",
    "\n",
    "        ax[axi].tick_params(labelsize=12)\n",
    "        ax[axi].set_xticks(range(len(labels)))\n",
    "        ax[axi].set_xticklabels(labels, rotation=90)\n",
    "        ax[axi].set_title(title[axi])\n",
    "    \n",
    "    ax[0].legend(loc=\"best\")\n",
    "    ax[-1].set_xlabel(\"Protein Residues\", fontsize=12)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_protein([pro_dict],[\"Purity Values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge together the two GLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict = deepcopy(pro_dict)\n",
    "mdict[\"Target\"] = {}\n",
    "mdict[\"Target\"][10] = mdict[\"GLY\"][10]\n",
    "mdict[\"Target\"][10] += mdict[\"GLY\"][11]\n",
    "del mdict[\"GLY\"][10]\n",
    "del mdict[\"GLY\"][11]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second GLY with the neighboring SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"GLY-SER\"] = {}\n",
    "mdict[\"GLY-SER\"][15] = mdict[\"GLY\"][15]\n",
    "mdict[\"GLY-SER\"][15] += mdict[\"SER\"][14]\n",
    "mdict[\"GLY-SER\"][15] += mdict[\"SER\"][13]\n",
    "del mdict[\"SER\"][14]\n",
    "del mdict[\"SER\"][13]\n",
    "del mdict[\"GLY\"][15]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the entire GLY-PRO-GLY portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"Target\"][10] += mdict[\"PRO\"][12]\n",
    "mdict[\"Target\"][10] += mdict[\"GLY-SER\"][15]\n",
    "del mdict[\"PRO\"][12]\n",
    "del mdict[\"GLY-SER\"][15]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"PRO\"][17] += mdict[\"PRO\"][18]\n",
    "mdict[\"PRO\"][17] += mdict[\"PRO\"][19]\n",
    "del mdict[\"PRO\"][18]\n",
    "del mdict[\"PRO\"][19]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LYS and ASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"GLY-ASP\"] = {}\n",
    "mdict[\"GLY-ASP\"][8] = mdict[\"LYS\"][8]\n",
    "mdict[\"GLY-ASP\"][8] += mdict[\"ASP\"][9]\n",
    "del mdict[\"ASP\"][9]\n",
    "del mdict[\"LYS\"][8]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"LEU-TYR\"] = {}\n",
    "mdict[\"LEU-TYR\"][2] = mdict[\"LEU\"][2]\n",
    "mdict[\"LEU-TYR\"][2] += mdict[\"TYR\"][3]\n",
    "del mdict[\"LEU\"][2]\n",
    "del mdict[\"TYR\"][3]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"TRP-LEU\"] = {}\n",
    "mdict[\"TRP-LEU\"][6] = mdict[\"TRP\"][6]\n",
    "mdict[\"TRP-LEU\"][6] += mdict[\"LEU\"][7]\n",
    "del mdict[\"TRP\"][6]\n",
    "del mdict[\"LEU\"][7]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict[\"ILE-GLN\"] = {}\n",
    "mdict[\"ILE-GLN\"][4] = mdict[\"ILE\"][4]\n",
    "mdict[\"ILE-GLN\"][4] += mdict[\"GLN\"][5]\n",
    "del mdict[\"ILE\"][4]\n",
    "del mdict[\"GLN\"][5]\n",
    "plot_protein([pro_dict, mdict], [\"Initial Fragmentation\", \"Merged\"], \"Pictures/merged.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally lets put this fragmentation information back into the full dictionary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frags = deepcopy(re_dict)\n",
    "\n",
    "for fname in pro_dict:\n",
    "    for fid in pro_dict[fname]:\n",
    "        del new_frags[fname][fid]\n",
    "new_frags = {k: v for k, v in new_frags.items() if any(v)}\n",
    "\n",
    "for fname in mdict:\n",
    "    if not fname in new_frags:\n",
    "        new_frags[fname] = {}\n",
    "    for fid in mdict[fname]:\n",
    "        new_frags[fname][fid] = mdict[fname][fid]\n",
    "print(new_frags.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also write a YAML file and use it to recompute all the Multipoles associated with this new fragmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_atoms = []\n",
    "for fname in pro_dict:\n",
    "    for fid in pro_dict[fname]:\n",
    "        protein_atoms.extend(pro_dict[fname][fid])\n",
    "        \n",
    "with open(\"new_frag_list.yaml\", \"w\") as ofile:\n",
    "    for fname in new_frags:\n",
    "        for fid in new_frags[fname]:\n",
    "            ofile.write(\"- \")\n",
    "            ofile.write(str(new_frags[fname][fid]))\n",
    "            ofile.write(\"\\n\")\n",
    "    ofile.write(\"- \")\n",
    "    ofile.write(str(protein_atoms))\n",
    "    ofile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spillage Analysis\n",
    "The next step is the spillage analysis. What we want to do now is to compute spillage values from fragment to fragment, not just fragment to atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMMM:\n",
    "    def __init__(self, frag_dict, target, target_name):\n",
    "        from copy import deepcopy\n",
    "        self.fdict = deepcopy(frag_dict)\n",
    "        self.target = target\n",
    "        self.target_name = target_name\n",
    "        \n",
    "        self.compute_frag_list()\n",
    "        \n",
    "    def compute_frag_list(self):\n",
    "        self.frag_list = []\n",
    "        for fname in self.fdict.keys():\n",
    "            for fid in self.fdict[fname].keys():\n",
    "                self.frag_list.append(self.fdict[fname][fid])\n",
    "                \n",
    "    def compute_spillage(self, param):\n",
    "        from numpy import trace\n",
    "        \n",
    "        self.val_list = []\n",
    "        if (len(self.target)) == 0:\n",
    "            return 0\n",
    "        indices_f = []\n",
    "    \n",
    "        for atom in self.target:\n",
    "            indices_f += param.atom_to_basis[atom-1]\n",
    "            \n",
    "        denom = param.sinvxh[:,indices_f]\n",
    "        denom = denom[indices_f,:]\n",
    "        denom = denom.todense()\n",
    "        denom = denom.dot(denom)\n",
    "        self.denom_t = trace(denom)\n",
    "\n",
    "        H2T = param.sinvxh2[:,indices_f]\n",
    "        H2T = H2T[indices_f,:]\n",
    "        self.left_t = trace(H2T.todense())\n",
    "\n",
    "        for frag_G in self.frag_list:\n",
    "            indices_g = []\n",
    "            for atom in frag_G:\n",
    "                indices_g += param.atom_to_basis[atom-1]\n",
    "\n",
    "            TFH = param.sinvxh[indices_f,:]\n",
    "            TFHTG = TFH[:,indices_g].todense()\n",
    "\n",
    "            TGH = param.sinvxh[indices_g,:]\n",
    "            TGHTF = TGH[:,indices_f].todense()\n",
    "\n",
    "            right_mat = (TFHTG.dot(TGHTF))\n",
    "            val = trace(right_mat)\n",
    "            self.val_list.append(val)\n",
    "        self.spillage_values = self.val_list/self.denom_t\n",
    "        \n",
    "    def plot(self, ax, marker):\n",
    "        ax.plot(sorted(self.spillage_values, reverse=True), marker=marker, \n",
    "                markersize=10, label=self.target_name)\n",
    "        \n",
    "    def compute_buffer(self, threshold):\n",
    "        buffer_region_frags = []\n",
    "        for j in range(0, len(self.spillage_values)):\n",
    "            if abs (self.spillage_values[j]) > threshold:\n",
    "                buffer_region_frags.append(j)\n",
    "        buffer_region_atoms = []    \n",
    "        for frag in buffer_region_frags:\n",
    "            for atom in self.frag_list[frag]:\n",
    "                buffer_region_atoms.append(atom)\n",
    "        return buffer_region_frags, buffer_region_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the spillage values from the full protein to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_env_dict = deepcopy(re_dict)\n",
    "\n",
    "prot_env_dict[\"Mini-Protein\"] = {}\n",
    "prot_env_dict[\"Mini-Protein\"][1] = []\n",
    "for fname in pro_dict:\n",
    "    for fid in pro_dict[fname]:\n",
    "        prot_env_dict[\"Mini-Protein\"][1] += re_dict[fname][fid]\n",
    "        del prot_env_dict[fname][fid]\n",
    "prot_env_dict = {k: v for k, v in prot_env_dict.items() if any(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QMMM_dict = {}\n",
    "temp = QMMM(new_frags, new_frags[\"Target\"][10], \"Target\")\n",
    "QMMM_dict[\"Target\"] = deepcopy(temp)\n",
    "QMMM_dict[\"Target\"].compute_spillage(data)\n",
    "\n",
    "temp = QMMM(new_frags, new_frags[\"Cl Cluster\"][567], \"Cl Cluster 567\")\n",
    "QMMM_dict[\"Cl Cluster 567\"] = deepcopy(temp)\n",
    "QMMM_dict[\"Cl Cluster 567\"].compute_spillage(data)\n",
    "\n",
    "temp = QMMM(new_frags, new_frags[\"Cl Cluster\"][568], \"Cl Cluster 568\")\n",
    "QMMM_dict[\"Cl Cluster 568\"] = deepcopy(temp)\n",
    "QMMM_dict[\"Cl Cluster 568\"].compute_spillage(data)\n",
    "\n",
    "temp = QMMM(new_frags, new_frags[\"Na Cluster\"][566], \"Na Cluster\")\n",
    "QMMM_dict[\"Na Cluster\"] = deepcopy(temp)\n",
    "QMMM_dict[\"Na Cluster\"].compute_spillage(data)\n",
    "\n",
    "temp = QMMM(prot_env_dict, prot_env_dict[\"Mini-Protein\"][1], \"Mini-Protein\")\n",
    "QMMM_dict[\"Mini-Protein\"] = deepcopy(temp)\n",
    "QMMM_dict[\"Mini-Protein\"].compute_spillage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Fragment\",fontsize=14)\n",
    "ax.set_ylabel(\"Spillage Contribution\",fontsize=14)\n",
    "ax.set_title(\"Largest 100 Fragments\", fontsize=14)\n",
    "ax.set_xlim(-3,100)\n",
    "ax.set_ylim(1e-10,5)\n",
    "\n",
    "system_labels=[\"Cl Cluster 567\", \"Cl Cluster 568\", \"Na Cluster\", \"Target\", \"Mini-Protein\"]\n",
    "\n",
    "markers = ['^', 'h', 'o', 'x', '|']\n",
    "for d, m in zip(system_labels, markers):\n",
    "    QMMM_dict[d].plot(ax, m)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "fig.savefig(\"Pictures/Spillage.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large of a buffer would each of these targets need to hit ten to the minus four?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout.write(\"Threshold \")\n",
    "for header in system_labels:\n",
    "    sys.stdout.write(\" & \"+header)\n",
    "sys.stdout.write(\"\\\\\\\\\\n\")\n",
    "print(\"\\midrule\")\n",
    "for thresh in [2, 3, 4, 5, 6, 7, 8]:\n",
    "    threshold = 10**(-1*thresh)\n",
    "    sys.stdout.write(\"$1.0 \\\\times 10^{-\"+str(thresh)+\"}$\")\n",
    "    \n",
    "    for t in system_labels:\n",
    "        target_size = len(QMMM_dict[t].target)\n",
    "        region_frag, region_atom = QMMM_dict[t].compute_buffer(threshold)\n",
    "        sys.stdout.write(\" & \"+str(len(region_atom)-target_size))\n",
    "    sys.stdout.write(\"\\\\\\\\\")\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of QM/MM Regions\n",
    "Now we will prepare the QM/MM input files for each of the target/buffer combinations. First we load in the input minimal file from the full run. Second, we read the file that has the multipole values for each of the fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load\n",
    "with open(\"mindna.yaml\") as ifile:\n",
    "    min_param = load(ifile)\n",
    "with open(\"Matrices/log.yaml\") as ifile:\n",
    "    multi_val = load(ifile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the basic parameters based on the minimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_template = deepcopy(min_param)\n",
    "output_template[\"posinp\"] = deepcopy(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the multipole value file we need to extract the multipoles and positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "m_values = deepcopy(multi_val[\"Multipole coefficients\"])\n",
    "p_values = deepcopy(positions)\n",
    "\n",
    "output_template[\"posinp\"] = deepcopy(p_values)\n",
    "output_template[\"dft\"][\"external_potential\"] = m_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_charge(atom_list):\n",
    "    cv = 0\n",
    "    for atom in atom_list:\n",
    "        cv += charge[atom-1]\n",
    "    if int(cv) % 8 == 0:\n",
    "        return 0\n",
    "    elif int(cv) % 8 > 4:\n",
    "        return -1.0\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_charge2(atom_list):\n",
    "    cv = 0\n",
    "    for atom in atom_list:\n",
    "        nzion = multi_val[\"Multipole coefficients\"][\"values\"][atom-1][\"nzion\"]\n",
    "        q0 = multi_val[\"Multipole coefficients\"][\"values\"][atom-1][\"q0\"][0]\n",
    "        cv += nzion + q0\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each threshold and system we have to generate the required buffer positions, and the inverse of the multipole coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import dump\n",
    "for thresh in [2, 3, 4, 5, 6, 7, 8]:\n",
    "    threshold = 10**(-1*thresh)\n",
    "    for t in QMMM_dict:\n",
    "        out_name = t+\"-\"+str(thresh)+\".yaml\"\n",
    "        frag_name = t+\"-\"+str(thresh)+\"-frag.yaml\"\n",
    "        region_frag, region_atom = QMMM_dict[t].compute_buffer(threshold)\n",
    "        new_pos = []\n",
    "        for atom in region_atom:\n",
    "            new_pos.append(positions[\"positions\"][atom-1])\n",
    "        new_m = []\n",
    "        for i in range(0, len(m_values[\"values\"])):\n",
    "            if i+1 not in region_atom:\n",
    "                new_m.append(m_values[\"values\"][i])\n",
    "        out_dict = deepcopy(output_template)\n",
    "        out_dict[\"dft\"][\"external_potential\"][\"values\"] = new_m\n",
    "        out_dict[\"posinp\"][\"positions\"] = new_pos\n",
    "        c1 = fix_charge(region_atom)\n",
    "        c2 = fix_charge2(region_atom)\n",
    "        out_dict[\"dft\"][\"qcharge\"] = round(c2)\n",
    "        del out_dict[\"dft\"][\"external_potential\"]\n",
    "        \n",
    "        print(out_name)\n",
    "        with open(\"QMMMInput/\"+out_name, \"w\") as ifile:\n",
    "            dump(out_dict, ifile)\n",
    "            \n",
    "        target_list = []\n",
    "        for i, atom in enumerate(region_atom):\n",
    "            if atom in QMMM_dict[t].target:\n",
    "                target_list.append(i+1)\n",
    "            \n",
    "        with open(\"QMMMInput/\"+frag_name, \"w\") as ofile:\n",
    "            dump([target_list], ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
